# -*- coding: utf-8 -*-
"""MusicRecommendation - ColabFiltering.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1dWw2qSgJ_6D7a5rzjk3Poj4Nkm6tyifh
"""

import pandas as pd
import numpy as np
from zipfile import ZipFile
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from pathlib import Path
import matplotlib.pyplot as plt

from google.colab import drive
drive.mount('/content/drive/')

ratings = pd.read_fwf('/content/drive/My Drive/Colab Notebooks/Dataset/10000.txt')
ratings.columns = ['user_id', 'song_id', 'listen_count']
ratings.head()

#encoding users and songs as integer indices.

user_ids = ratings["user_id"].unique().tolist()
user2user_encoded = {x: i for i, x in enumerate(user_ids)}
userencoded2user = {i: x for i, x in enumerate(user_ids)}
song_ids = ratings["song_id"].unique().tolist()
song2song_encoded = {x: i for i, x in enumerate(song_ids)}
song_encoded2song = {i: x for i, x in enumerate(song_ids)}
ratings["user"] = ratings["user_id"].map(user2user_encoded)
ratings["song"] = ratings["song_id"].map(song2song_encoded)

num_users = len(user2user_encoded)
num_songs = len(song_encoded2song)
ratings["listen_count"] = ratings["listen_count"].values.astype(np.float32)
# in order to normalize the ratings later
min_rating = min(ratings["listen_count"])
max_rating = max(ratings["listen_count"])

num_users, num_songs, min_rating, max_rating

# Preparing training and validation data
df = ratings.sample(frac=1, random_state=42)
x = df[["user", "song"]].values
# Normalizing the targets between 0 and 1 (Easier to train).
y = df["listen_count"].apply(lambda x: (x - min_rating) / (max_rating - min_rating)).values
# Training on 80% of the data and validating on 20%.
train_indices = int(0.8 * df.shape[0])
x_train, x_val, y_train, y_val = (
    x[:train_indices],
    x[train_indices:],
    y[:train_indices],
    y[train_indices:],
)

EMBEDDING_SIZE = 50

#Embed users and songs in to 50-dimensional vectors.
#The model will compute a score between user and song embeddings through a dot product,
#and add a per-song and per-user bias. The match score is scaled to the `[0, 1]`
#interval through a sigmoid (since ratings are normalized to this range).

class RecommenderNet(keras.Model):
    def __init__(self, num_users, num_songs, embedding_size, **kwargs):
        super(RecommenderNet, self).__init__(**kwargs)
        self.num_users = num_users
        self.num_songs = num_songs
        self.embedding_size = embedding_size
        self.user_embedding = layers.Embedding(
            num_users,
            embedding_size,
            embeddings_initializer="he_normal",
            embeddings_regularizer=keras.regularizers.l2(1e-6),
        )
        self.user_bias = layers.Embedding(num_users, 1)
        self.song_embedding = layers.Embedding(
            num_songs,
            embedding_size,
            embeddings_initializer="he_normal",
            embeddings_regularizer=keras.regularizers.l2(1e-6),
        )
        self.song_bias = layers.Embedding(num_songs, 1)

    def call(self, inputs):
        user_vector = self.user_embedding(inputs[:, 0])
        user_bias = self.user_bias(inputs[:, 0])
        song_vector = self.song_embedding(inputs[:, 1])
        song_bias = self.song_bias(inputs[:, 1])
        dot_user_song = tf.tensordot(user_vector, song_vector, 2)
        # Add all the components (including bias)
        x = dot_user_song + user_bias + song_bias
        # The sigmoid activation forces the rating to between 0 and 1
        return tf.nn.sigmoid(x)

model = RecommenderNet(num_users, num_songs, EMBEDDING_SIZE)
model.summary
model.compile(
    loss=tf.keras.losses.BinaryCrossentropy(), optimizer=keras.optimizers.Adam(lr=0.001), metrics=['accuracy']
)

# Train the model based on the data split
history = model.fit(
    x=x_train,
    y=y_train,
    batch_size=64,
    epochs=30,
    verbose=1,
    validation_data=(x_val, y_val),
)



